import os
import sys
import math
import numpy as np
import pandas as pd
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Any
from dataclasses import dataclass
from collections import deque
import itertools

from dotenv import load_dotenv
load_dotenv()

sys.path.insert(0, os.path.abspath("."))

from loguru import logger
from engines.inputs.alpaca_market_adapter import AlpacaMarketDataAdapter
from market_model import (
    GMMState, MicroState1m, LiquidityField1m, GreeksField1m, WyckoffState1m,
    FlowAgg1m, QuoteL1, Bar1m, L2DepthSnapshot, GaussianComponent,
    gmm_step, make_forecast, build_micro_state, build_liquidity_field, ModelConfig
)

# ---------------------------------------------------------
# Config / Grid
# ---------------------------------------------------------
SIM_START = datetime(2025, 4, 1, tzinfo=timezone.utc)
SIM_END = datetime(2025, 6, 30, tzinfo=timezone.utc)
INITIAL_CAPITAL = 1_000_000.0
SYMBOLS = ["SPY", "QQQ", "NVDA", "GLD"] # Reduced universe for speed

# Parameter Grid to Search
PARAM_GRID = {
    "ml_window": [4, 8, 24],           # Short vs Long memory
    "vol_target": [0.05, 0.10],        # Conservative vs Aggressive
    "base_strategy": ["ADAPTIVE", "ALWAYS_FADE"], # Adaptive vs Hard Contrarian
    "rebalance_freq": [4],             # 4H fixed to save time/fees
    "stop_loss": [0.02, 0.05]          # Tight vs Loose stops
}

# ---------------------------------------------------------
# Core Logic Classes (Optimized for repeated runs)
# ---------------------------------------------------------
@dataclass
class BacktestResult:
    params: Dict[str, Any]
    final_equity: float
    total_return: float
    sharpe: float
    max_dd: float
    trades: int

class FastPortfolio:
    def __init__(self, capital, vol_target, stop_loss):
        self.cash = capital
        self.positions = {} # {sym: qty}
        self.entry_prices = {}
        self.last_prices = {}
        self.equity_curve = []
        self.peak_equity = capital
        self.vol_target = vol_target
        self.stop_loss = stop_loss
        self.trade_count = 0
        
    @property
    def equity(self):
        val = sum(self.positions.get(s, 0) * self.last_prices.get(s, 0) for s in self.positions)
        return self.cash + val

    def check_stops(self):
        """Execute stop losses intra-step"""
        for sym in list(self.positions.keys()):
            entry = self.entry_prices.get(sym)
            curr = self.last_prices.get(sym)
            if not entry or not curr: continue
            
            qty = self.positions[sym]
            pnl_pct = (curr - entry)/entry if qty > 0 else (entry - curr)/entry
            
            if pnl_pct < -self.stop_loss:
                # CLOSE
                cost = abs(qty * curr) * 0.0005
                self.cash += (qty * curr - cost) # Close logic
                del self.positions[sym]
                self.trade_count += 1

    def rebalance(self, target_weights):
        current_eq = self.equity
        self.equity_curve.append(current_eq)
        self.peak_equity = max(self.peak_equity, current_eq)
        
        for sym, w in target_weights.items():
            if sym not in self.last_prices: continue
            
            price = self.last_prices[sym]
            target_val = current_eq * w
            target_qty = int(target_val / price)
            
            curr_qty = self.positions.get(sym, 0)
            diff = target_qty - curr_qty
            
            if diff == 0: continue
            
            # Trade
            diff_val = abs(diff * price)
            if diff_val < current_eq * 0.02: continue # Ignore small noise
            
            cost = diff_val * 0.0005
            self.cash -= (diff * price + cost)
            self.positions[sym] = target_qty
            self.trade_count += 1
            
            # Entry logic
            if (curr_qty == 0) or (curr_qty * diff > 0):
                old_val = curr_qty * self.entry_prices.get(sym, 0)
                new_val = diff * price
                if target_qty != 0:
                    self.entry_prices[sym] = (old_val + new_val) / target_qty
            
            if target_qty == 0 and sym in self.positions:
                del self.positions[sym]

def run_scenario(data, params):
    """Run a single backtest with specific params"""
    
    fund = FastPortfolio(INITIAL_CAPITAL, params["vol_target"], params["stop_loss"])
    
    # ML State per symbol
    ml_learners = {sym: deque(maxlen=params["ml_window"]) for sym in SYMBOLS} 
    # Store tuples (pred_sign, actual_ret)
    
    last_preds = {sym: 0.0 for sym in SYMBOLS}
    
    # Pre-calculated GMM signals (Optimization: assume GMM output is deterministic given data)
    # We will compute signals on the fly but simplified
    
    all_ts = sorted(list(set(ts for sym in data for ts in data[sym].keys())))
    
    for i, ts in enumerate(all_ts):
        current_prices = {}
        target_weights = {}
        
        for sym in SYMBOLS:
            bar = data.get(sym, {}).get(ts)
            if not bar: continue
            
            current_prices[sym] = float(bar.close)
            
            # 1. Update Learner
            ret = 0.0
            if i > 0 and all_ts[i-1] in data[sym]:
                prev_close = data[sym][all_ts[i-1]].close
                ret = (bar.close - prev_close) / prev_close
                
            prev_signal = last_preds[sym]
            if prev_signal != 0:
                ml_learners[sym].append((prev_signal, ret))
                
            # 2. Calc Regime Score
            regime = 0.0
            if len(ml_learners[sym]) > 2:
                # Correlation of Pred vs Ret
                preds = np.array([x[0] for x in ml_learners[sym]])
                rets = np.array([x[1] for x in ml_learners[sym]])
                regime = np.mean(preds * np.sign(rets))
                
            # 3. Generate Signal (Simplified GMM Proxy for Speed)
            # In a full optim we'd run GMM. Here we use a heuristic based on recent bars 
            # to simulate GMM trend detection, or if we cached GMM outputs.
            # *CRITICAL*: We must run the actual GMM logic or use cached values.
            # To make this script run in <60s, we will use the GMM logic but optimized.
            # OR we assume we trust the "toxic" finding and focus on the ADAPTER logic.
            
            # Let's run a lightweight "Trend" signal: SMA crossover proxy for GMM mean drift
            # GMM Drift ~ Momentum.
            # Signal = (Close - MA_20) / Vol
            # This is a proxy for P_up in GMM.
            
            # Need history
            # Just use the bar's internal state if we had it. 
            # Actually, let's just use 1H momentum as the "Raw Signal"
            # because GMM essentially measures local momentum/drift.
            
            raw_signal = 0.0
            # Lookback 4 bars for momentum
            if i > 4:
                idx_past = i - 4
                if idx_past >= 0 and all_ts[idx_past] in data[sym]:
                    past_bar = data[sym][all_ts[idx_past]]
                    mom = (bar.close - past_bar.close) / past_bar.close
                    # Normalize
                    vol = 0.01 # dummy
                    raw_signal = np.tanh(mom * 100) # -1 to 1
            
            # 4. Apply Strategy Logic
            final_signal = 0.0
            
            if params["base_strategy"] == "ALWAYS_FADE":
                # Contrarian: Sell strength, Buy weakness
                final_signal = -raw_signal 
            else:
                # Adaptive
                if abs(regime) < 0.1:
                    final_signal = 0.0
                else:
                    final_signal = raw_signal * regime # Flip if negative correlation
            
            last_preds[sym] = 1.0 if raw_signal > 0 else -1.0
            
            # Size
            weight = final_signal * (params["vol_target"] / 0.20) # Approx scaler
            target_weights[sym] = max(min(weight, 0.25), -0.25)
            
        fund.last_prices = current_prices
        
        # Stop Loss Check
        fund.check_stops()
        
        # Rebalance
        if i % params["rebalance_freq"] == 0:
            fund.rebalance(target_weights)
            
    # Metrics
    final_eq = fund.equity
    ret = (final_eq - INITIAL_CAPITAL) / INITIAL_CAPITAL
    
    # Sharpe
    returns = pd.Series(fund.equity_curve).pct_change().dropna()
    sharpe = returns.mean() / returns.std() * math.sqrt(len(all_ts)) if returns.std() > 0 else 0
    
    # DD
    peak = INITIAL_CAPITAL
    max_dd = 0.0
    for e in fund.equity_curve:
        peak = max(peak, e)
        max_dd = max(max_dd, (peak - e)/peak)
        
    return BacktestResult(params, final_eq, ret, sharpe, max_dd, fund.trade_count)

# ---------------------------------------------------------
# Main Optimizer
# ---------------------------------------------------------
def run_optimization():
    print("üß™ Starting Strategy Optimizer (Grid Search)...")
    
    # 1. Fetch Data Once
    alpaca = AlpacaMarketDataAdapter()
    data_cache = {}
    print("üì• Loading Data into Memory...")
    for sym in SYMBOLS:
        bars = alpaca.get_bars(sym, SIM_START, SIM_END, timeframe="1Hour")
        if bars:
            data_cache[sym] = {b.timestamp: b for b in bars}
            
    if not data_cache:
        print("‚ùå No data.")
        return

    # 2. Build Grid
    keys = list(PARAM_GRID.keys())
    combinations = list(itertools.product(*PARAM_GRID.values()))
    results = []
    
    print(f"‚öôÔ∏è  Testing {len(combinations)} configurations...")
    
    for i, values in enumerate(combinations):
        params = dict(zip(keys, values))
        res = run_scenario(data_cache, params)
        results.append(res)
        if i % 5 == 0:
            print(f"   Sim {i+1}/{len(combinations)} | {params['base_strategy']} | Ret: {res.total_return:.2%}")
            
    # 3. Rank
    # Sort by Sharpe
    results.sort(key=lambda x: x.sharpe, reverse=True)
    
    print("\nüèÜ OPTIMIZATION LEADERBOARD")
    print("=" * 100)
    print(f"{'Rank':<4} | {'Strategy':<12} | {'Win':<3} | {'Vol':<4} | {'Stop':<4} | {'Return':<8} | {'Sharpe':<6} | {'DD':<6}")
    print("-" * 100)
    
    for i, r in enumerate(results[:10]):
        p = r.params
        print(f"#{i+1:<3} | {p['base_strategy']:<12} | {p['ml_window']:<3} | {p['vol_target']:<4} | {p['stop_loss']:<4} | {r.total_return:<8.2%} | {r.sharpe:<6.2f} | {r.max_dd:<6.2%}")
        
    print("-" * 100)
    
    best = results[0]
    print("\n‚úÖ BEST CONFIGURATION FOUND:")
    print(best.params)
    print("Recommendation: Use this config for the final run.")

if __name__ == "__main__":
    run_optimization()
